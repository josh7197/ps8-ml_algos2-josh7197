{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 0**\n",
    "\n",
    "Run the cell below to make sure you are in the data1030 coding environment. \n",
    "\n",
    "We will deduct 2 points for every missing OK sign. (If you don't run the cell, that's -14 points.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from distutils.version import LooseVersion as Version\n",
    "import sys\n",
    "\n",
    "OK = '\\x1b[42m[ OK ]\\x1b[0m'\n",
    "FAIL = \"\\x1b[41m[FAIL]\\x1b[0m\"\n",
    "\n",
    "try:\n",
    "    import importlib\n",
    "except ImportError:\n",
    "    print(FAIL, \"Python version 3.9 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "\n",
    "def import_version(pkg, min_ver, fail_msg=\"\"):\n",
    "    mod = None\n",
    "    try:\n",
    "        mod = importlib.import_module(pkg)\n",
    "        if pkg in {'PIL'}:\n",
    "            ver = mod.VERSION\n",
    "        else:\n",
    "            ver = mod.__version__\n",
    "        if Version(ver) == min_ver:\n",
    "            print(OK, \"%s version %s is installed.\"\n",
    "                  % (lib, min_ver))\n",
    "        else:\n",
    "            print(FAIL, \"%s version %s is required, but %s installed.\"\n",
    "                  % (lib, min_ver, ver))    \n",
    "    except ImportError:\n",
    "        print(FAIL, '%s not installed. %s' % (pkg, fail_msg))\n",
    "    return mod\n",
    "\n",
    "\n",
    "# first check the python version\n",
    "pyversion = Version(sys.version)\n",
    "if pyversion >= \"3.9\":\n",
    "    print(OK, \"Python version is %s\" % sys.version)\n",
    "elif pyversion < \"3.9\":\n",
    "    print(FAIL, \"Python version 3.9 is required,\"\n",
    "                \" but %s is installed.\" % sys.version)\n",
    "else:\n",
    "    print(FAIL, \"Unknown Python version: %s\" % sys.version)\n",
    "\n",
    "    \n",
    "print()\n",
    "requirements = {'numpy': \"1.21.1\", 'matplotlib': \"3.4.2\",'sklearn': \"0.24.2\", \n",
    "                'pandas': \"1.3.1\",'xgboost': \"1.3.3\", 'shap': \"0.39.0\"}\n",
    "\n",
    "# now the dependencies\n",
    "for lib, required_version in list(requirements.items()):\n",
    "    import_version(lib, required_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1**\n",
    "\n",
    "One ML algorithm we didn't cover during class is the nearest neighbor algorithm. The principle behind nearest neighbor methods is to find a predefined number of training samples closest in distance to the new point, and predict the label from these nearest neighbors. The number of samples can be a user-defined constant (k-nearest neighbor learning), or vary based on the local density of points (distance-based neighbor learning). The distance can, in general, be any distance metric: standard Euclidean distance is the most common choice.\n",
    "\n",
    "Read more about this method [here](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification) and [here](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1a** (8 points)\n",
    "\n",
    "Nearest neighbor regression. Please import KNeighborsRegressor and read the manual. Let's study how the `n_neighbors` parameter impact the prediction.\n",
    "\n",
    "Please recreate the simple regression dataset from the lecture notes (n_samples = 30 with a cos function). (0 points)\n",
    "\n",
    "Prepare a plot that shows predictions for n_neighbors = 1, 3, 10, and 30. (2 points)\n",
    "\n",
    "Answer the following questions and explain your answer. (4 points)\n",
    "   - What `n_neighbors` value produces a high bias (low variance) model? What `n_neighbors` value produces a high variance (low bias) model? How do overfitting and underfitting manifest in nearest neighbor?\n",
    "   - How does the model behave with respect to outliers?\n",
    "   - Explain why the model prediction is a step function and how this step function differs from a decision tree step function?\n",
    "\n",
    "Based on the manual, what other parameter has a strong influence on the predictions? Prepare another figure to prove your point. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1b** (5 points)\n",
    "\n",
    "Nearest neighbor classification. Please import KNeighborsClassifier and read the manual. Let's study how the `n_neighbors` parameters impact the prediction.\n",
    "\n",
    "Please recreate the simple classification dataset from the lecture notes (makemoons). (0 points)\n",
    "\n",
    "Prepare a plot that shows predictions for n_neighbors = 1, 10, 30, and 100. (2 points)\n",
    "\n",
    "Prepare another plot with the same n_neighbors values but `weights` set to distance. (1 point)\n",
    "\n",
    "What is the biggest difference between the predicted probabilities of the two models? Explain your answer. (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2**\n",
    "\n",
    "You will work with the diabetes dataset and try different ML algorithms on it to figure out which one is the best. Whenever you work with a new dataset, you want to try as many algorithms on it as possible because you can't know in advance which algorithm (and hyperparameters) will be the best.\n",
    "\n",
    "Generally you need to decide five things when you build an ML pipeline:\n",
    "- your splitting strategy\n",
    "- how to preprocess the data\n",
    "- what evaluation metric you'll use\n",
    "- what ML algorithms you will try\n",
    "- what paramater grid you should use for each ML algorithm\n",
    "\n",
    "You'll write a function in problem 2a that takes a preprocessor, an ML algorithm, and its corresponding parameter grid as inputs and it will calculate test scores and return the best models. The splitting strategy and the evaluation metric are not inputs to this function but predefined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2a** (10 points)\n",
    "\n",
    "Write a function which takes the unprocessed feature matrix, target variable, a preprocessor (ColumnTransformer), an initialized ML algorithm, and a correspondig parameter grid as inputs. Inside the function, split the data to other and test (80-20) and then use KFold with 4 folds. Then preprocess the data and perform cross validation (I recommend you use GridSearchCV), then calculate the test score. Use RMSE as your evaluation metric. Repeat this 10 times for 10 different random states, and the function should return the 10 best models and the 10 test scores. The skeleton of the function is provided for convenince.\n",
    "\n",
    "The function name contains the splitting strategy and the evaluation metric. It would be difficult (but not impossible) to write a general `MLpipe` function that takes a splitter and an evaluation metric also as inputs for two reasons:\n",
    "- some splitters are difficult to pass as a function argument (e.g., two train_test_split steps, or a train_test_split combined with a KFold),\n",
    "- some evaluation metrics need to be maximized (like accuracy, R2, f_beta), while others need to be minimized (like logloss, RMSE) and the code for these two options differ.\n",
    "\n",
    "For now, I recommend that if you need to try multiple ML algorithms, write a function that's specific to a splitting strategy and an evaluation metric and add a description to the function as shown in MLpipe_KFold_RMSE. Such functions make it very easy to try many ML algorithms on your dataset and I recommend you write a similar function for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MLpipe_KFold_RMSE(X, y, preprocessor, ML_algo, param_grid):\n",
    "    '''\n",
    "    This function splits the data to other/test (80/20) and then applies KFold with 4 folds to other.\n",
    "    The RMSE is minimized in cross-validation.\n",
    "    '''\n",
    "\n",
    "    return best_models, test_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2b** (16 points)\n",
    "\n",
    "Then train following models on the diabetes dataset:\n",
    "- linear regression with l1 regularization (already completed in 2a)\n",
    "- linear regression with l2 regularization (2 points)\n",
    "- linear regression with an elastic net (3 points)\n",
    "- RF (4 points)\n",
    "- SVR (3 points)\n",
    "- k nearest neighbor regression (3 points)\n",
    "\n",
    "Please determine what the parameter grid should be for each of these methods. Please follow the guidance from the previous exercises and the lecture notes.\n",
    "\n",
    "Make sure your code is reproducable! When you rerun it, you should get back the exact same test scores and best hyperparameters in each run. So fix your random states whereever necessary.\n",
    "\n",
    "Which algorithm is the best on the diabetes dataset based on the mean and standard deviation of the test scores? Write a paragraph or two and describe your findings. (1 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ElasticNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
